import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { GoogleGenAI } from "npm:@google/genai@1.29.1";
import { createClient } from "npm:@supabase/supabase-js@2.50.0";

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
  "Access-Control-Allow-Methods": "POST, OPTIONS",
};

function getAiClient(): GoogleGenAI {
  const apiKey = Deno.env.get("GEMINI_API_KEY");
  if (!apiKey) throw new Error("Missing GEMINI_API_KEY");
  return new GoogleGenAI({ apiKey });
}

function getSupabaseAdmin() {
  const supabaseUrl = Deno.env.get("SUPABASE_URL");
  const supabaseServiceKey = Deno.env.get("SUPABASE_SERVICE_ROLE_KEY");
  if (!supabaseUrl || !supabaseServiceKey) {
    throw new Error("Missing Supabase environment variables");
  }
  return createClient(supabaseUrl, supabaseServiceKey);
}

// Custom RAG handler
async function handleCustomRagChat(supabase: any, storeId: string, messages: any[], sessionId: string) {
  const lastUserMessage = messages[messages.length - 1];
  
  // Get store config
  const { data: store } = await supabase
    .from('custom_rag_stores')
    .select('*')
    .eq('id', storeId)
    .single();

  if (!store) throw new Error("Custom RAG store not found");

  // Generate embedding for query
  const embedding = await generateEmbedding(
    lastUserMessage.content,
    store.embedding_model,
    store.embedding_dimensions
  );

  // Search chunks
  const { data: chunks } = await supabase.rpc('match_custom_rag_chunks', {
    query_embedding: `[${embedding.join(',')}]`,
    p_store_id: storeId,
    match_threshold: 0.3,
    match_count: 30,
  });

  // Build context
  const context = chunks?.map((c: any) => c.content).join('\n\n---\n\n') || '';

  // Generate response with Gemini
  const ai = getAiClient();
  const response = await ai.models.generateContent({
    model: 'gemini-2.5-flash',
    contents: [{
      role: 'user',
      parts: [{ text: `Context:\n${context}\n\nSoru: ${lastUserMessage.content}` }]
    }],
    config: { temperature: 0.1 }
  });

  const text = response.candidates?.[0]?.content?.parts?.[0]?.text || '';

  return new Response(
    JSON.stringify({ text, sources: chunks?.map((c: any) => c.document_name) || [], customRag: true }),
    { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
  );
}

async function generateEmbedding(text: string, model: string, dimensions: number): Promise<number[]> {
  if (model === 'gemini') {
    const ai = getAiClient();
    const result = await ai.models.embedContent({
      model: 'models/text-embedding-004',
      contents: [{ parts: [{ text }] }],
      config: {
        taskType: 'RETRIEVAL_QUERY',
        outputDimensionality: dimensions,
      },
    });
    return result.embeddings[0].values;
  } else {
    const response = await fetch('https://api.openai.com/v1/embeddings', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${Deno.env.get('OPENAI_API_KEY')}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'text-embedding-3-large',
        input: text,
        dimensions: dimensions,
      }),
    });
    const data = await response.json();
    return data.data[0].embedding;
  }
}

const cleanProvince = (text: string): string => {
  let cleaned = text
    .replace(/'da$/i, "")
    .replace(/'de$/i, "")
    .replace(/\sda$/i, "")
    .replace(/\sde$/i, "")
    .replace(/\sta$/i, "")
    .replace(/\ste$/i, "")
    .replace(/\sili$/i, "")
    .replace(/\sƒ∞li$/i, "")
    .trim();

  if (!cleaned) return text.trim();
  return cleaned.charAt(0).toUpperCase() + cleaned.slice(1);
};

const cleanDistrict = (text: string): string => {
  const cleaned = text.trim();
  if (!cleaned) return text.trim();
  return cleaned.charAt(0).toUpperCase() + cleaned.slice(1);
};

const parseOsbStatus = (text: string): "ƒ∞√áƒ∞" | "DI≈ûI" | null => {
  const lower = text.toLowerCase().trim();
  if (
    lower.includes("i√ßi") ||
    lower.includes("i√ßinde") ||
    lower.includes("osb i√ßi") ||
    lower.includes("organize sanayi i√ßi") ||
    lower === "i√ßi" ||
    lower === "ici" ||
    lower === "evet" ||
    lower === "var"
  ) {
    return "ƒ∞√áƒ∞";
  }
  if (
    lower.includes("dƒ±≈üƒ±") ||
    lower.includes("dƒ±≈üƒ±nda") ||
    lower.includes("osb dƒ±≈üƒ±") ||
    lower === "dƒ±≈üƒ±" ||
    lower === "disi" ||
    lower.includes("hayƒ±r") ||
    lower.includes("hayir") ||
    lower.includes("deƒüil") ||
    lower.includes("degil") ||
    lower === "yok"
  ) {
    return "DI≈ûI";
  }
  return null;
};

// T√ºrkiye'deki t√ºm il isimleri
const TURKISH_PROVINCES = [
  "Adana",
  "Adƒ±yaman",
  "Afyonkarahisar",
  "Aƒürƒ±",
  "Aksaray",
  "Amasya",
  "Ankara",
  "Antalya",
  "Ardahan",
  "Artvin",
  "Aydƒ±n",
  "Balƒ±kesir",
  "Bartƒ±n",
  "Batman",
  "Bayburt",
  "Bilecik",
  "Bing√∂l",
  "Bitlis",
  "Bolu",
  "Burdur",
  "Bursa",
  "√áanakkale",
  "√áankƒ±rƒ±",
  "√áorum",
  "Denizli",
  "Diyarbakƒ±r",
  "D√ºzce",
  "Edirne",
  "Elazƒ±ƒü",
  "Erzincan",
  "Erzurum",
  "Eski≈üehir",
  "Gaziantep",
  "Giresun",
  "G√ºm√º≈ühane",
  "Hakkari",
  "Hatay",
  "Iƒüdƒ±r",
  "Isparta",
  "ƒ∞stanbul",
  "ƒ∞zmir",
  "Kahramanmara≈ü",
  "Karab√ºk",
  "Karaman",
  "Kars",
  "Kastamonu",
  "Kayseri",
  "Kilis",
  "Kƒ±rƒ±kkale",
  "Kƒ±rklareli",
  "Kƒ±r≈üehir",
  "Kocaeli",
  "Konya",
  "K√ºtahya",
  "Malatya",
  "Manisa",
  "Mardin",
  "Mersin",
  "Muƒüla",
  "Mu≈ü",
  "Nev≈üehir",
  "Niƒüde",
  "Ordu",
  "Osmaniye",
  "Rize",
  "Sakarya",
  "Samsun",
  "≈ûanlƒ±urfa",
  "Siirt",
  "Sinop",
  "Sivas",
  "≈ûƒ±rnak",
  "Tekirdaƒü",
  "Tokat",
  "Trabzon",
  "Tunceli",
  "U≈üak",
  "Van",
  "Yalova",
  "Yozgat",
  "Zonguldak",
];

const normalizeRegionNumbers = (text: string): string => {
  const replacements: Record<string, string> = {
    "birinci b√∂lge": "1. B√∂lge",
    "ikinci b√∂lge": "2. B√∂lge",
    "√º√ß√ºnc√º b√∂lge": "3. B√∂lge",
    "d√∂rd√ºnc√º b√∂lge": "4. B√∂lge",
    "be≈üinci b√∂lge": "5. B√∂lge",
    "altƒ±ncƒ± b√∂lge": "6. B√∂lge",
    "altinci b√∂lge": "6. B√∂lge",
    "birinci b√∂lgedeli": "1. B√∂lge",
    "ikinci b√∂lgedeli": "2. B√∂lge",
    "√º√ß√ºnc√º b√∂lgedeli": "3. B√∂lge",
    "d√∂rd√ºnc√º b√∂lgedeli": "4. B√∂lge",
    "be≈üinci b√∂lgedeli": "5. B√∂lge",
    "altƒ±ncƒ± b√∂lgedeli": "6. B√∂lge",
    "altinci b√∂lgedeli": "6. B√∂lge",
  };

  let normalized = text;
  for (const [pattern, replacement] of Object.entries(replacements)) {
    const regex = new RegExp(pattern, "gi");
    normalized = normalized.replace(regex, replacement);
  }

  return normalized;
};

// FIX 1: Robustly filter out internal tool and thought content (tool call leakage).
function extractTextAndChunks(response: any) {
  const candidate = response?.candidates?.[0];
  const finishReason: string | undefined = candidate?.finishReason;
  const groundingChunks = candidate?.groundingMetadata?.groundingChunks ?? [];
  const parts = candidate?.content?.parts ?? [];

  // ‚úÖ Detaylƒ± debug logging
  console.log("üîç extractTextAndChunks - Input Analysis:", {
    hasCandidates: !!response?.candidates,
    candidateCount: response?.candidates?.length || 0,
    finishReason,
    partsCount: parts.length,
    groundingChunksCount: groundingChunks.length,
  });

  const textPieces: string[] = [];

  for (const p of parts) {
    if (!p) continue;

    console.log("üìù Processing part:", {
      hasText: !!p.text,
      textLength: p.text?.length || 0,
      isThought: p.thought === true,
      hasCode: !!(p.executableCode || p.codeExecutionResult),
      hasFunctionCall: !!(p.functionCall || p.toolCall),
    });

    if (p.thought === true) {
      console.log("‚è≠Ô∏è Skipping thought part");
      continue;
    }
    if (p.executableCode || p.codeExecutionResult) {
      console.log("‚è≠Ô∏è Skipping code execution part");
      continue;
    }
    if (p.functionCall || p.toolCall) {
      console.log("‚è≠Ô∏è Skipping tool call part");
      continue;
    }
    if (typeof p.text !== "string") {
      console.log("‚è≠Ô∏è Skipping non-string part");
      continue;
    }

    const t = p.text.trim();
    if (t.startsWith("tool_code") || t.startsWith("code_execution_result")) {
      console.log("‚è≠Ô∏è Skipping tool_code block");
      continue;
    }
    if (t.includes("file_search.query(")) {
      console.log("‚è≠Ô∏è Skipping file_search query");
      continue;
    }

    textPieces.push(p.text);
    console.log("‚úÖ Added text piece (length:", p.text.length, ")");
  }

  const textOut = textPieces.join("");

  console.log("üìä extractTextAndChunks - Final Result:", {
    totalTextLength: textOut.length,
    textPreview: textOut.substring(0, 150) + (textOut.length > 150 ? "..." : ""),
    groundingChunksCount: groundingChunks.length,
  });

  return { finishReason, groundingChunks, textOut };
}

serve(async (req) => {
  if (req.method === "OPTIONS") {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const { storeName, messages, sessionId } = await req.json();
    console.log("=== chat-gemini request ===");
    console.log("storeName:", storeName);
    console.log("sessionId:", sessionId);
    console.log("messages count:", messages?.length);

    const supabase = getSupabaseAdmin();

    // Check RAG mode
    const { data: ragModeData } = await supabase
      .from('admin_settings')
      .select('setting_value_text')
      .eq('setting_key', 'chatbot_rag_mode')
      .single();

    const ragMode = ragModeData?.setting_value_text || 'gemini_file_search';
    console.log("üîß RAG Mode:", ragMode);

    // If custom RAG mode, use custom RAG search
    if (ragMode === 'custom_rag') {
      const { data: customStoreData } = await supabase
        .from('admin_settings')
        .select('setting_value_text')
        .eq('setting_key', 'active_custom_rag_store')
        .single();

      const customStoreId = customStoreData?.setting_value_text;

      if (customStoreId) {
        console.log("üîç Using Custom RAG store:", customStoreId);
        // Delegate to custom RAG handler
        return await handleCustomRagChat(supabase, customStoreId, messages, sessionId);
      }
    }

    // Default: Use Gemini File Search (existing flow)
    if (!storeName) {
      throw new Error("storeName is required");
    }
    if (!Array.isArray(messages) || messages.length === 0) {
      throw new Error("messages must be a non-empty array");
    }

    const lastUserMessage = messages
      .slice()
      .reverse()
      .find((m: any) => m.role === "user");
    if (!lastUserMessage) {
      throw new Error("No user message found");
    }

    const lowerContent = lastUserMessage.content.toLowerCase();
    const isIncentiveRelated =
      lowerContent.includes("te≈üvik") ||
      lowerContent.includes("tesvik") ||
      lowerContent.includes("hesapla") ||
      lowerContent.includes("yatƒ±rƒ±m") ||
      lowerContent.includes("yatirim") ||
      lowerContent.includes("destek") ||
      lowerContent.includes("sekt√∂r") ||
      lowerContent.includes("sektor") ||
      lowerContent.includes("√ºretim") ||
      lowerContent.includes("uretim") ||
      lowerContent.includes("imalat");

    console.log("isIncentiveRelated:", isIncentiveRelated);

    let incentiveQuery: any = null;

    if (isIncentiveRelated && sessionId) {
      const { data: existingQuery, error: queryError } = await supabase
        .from("incentive_queries")
        .select()
        .eq("session_id", sessionId)
        .maybeSingle();

      if (queryError) {
        console.error("Error checking incentive_queries:", queryError);
      }

      if (existingQuery) {
        incentiveQuery = existingQuery;
        console.log("‚úì Found existing incentive query:", incentiveQuery);

        const userContent = lastUserMessage.content;
        let updated = false;

        // Note: The slot filling logic below is sequential and prone to the "greedy" problem.
        // It's left as is to match your original structure, but the prompt fixes
        // and history cleanup should make the chatbot's *output* cleaner.
        if (!incentiveQuery.sector) {
          incentiveQuery.sector = userContent;
          updated = true;
        } else if (!incentiveQuery.province) {
          const province = cleanProvince(userContent);
          incentiveQuery.province = province;
          updated = true;
        } else if (!incentiveQuery.district) {
          const district = cleanDistrict(userContent);
          incentiveQuery.district = district;
          updated = true;
        } else if (!incentiveQuery.osb_status) {
          const osbStatus = parseOsbStatus(userContent);
          if (osbStatus) {
            incentiveQuery.osb_status = osbStatus;
            updated = true;
          }
        }

        if (updated && incentiveQuery.id) {
          const allFilled =
            incentiveQuery.sector && incentiveQuery.province && incentiveQuery.district && incentiveQuery.osb_status;
          const newStatus = allFilled ? "complete" : "collecting";

          const { error: updateError } = await supabase
            .from("incentive_queries")
            .update({
              sector: incentiveQuery.sector,
              province: incentiveQuery.province,
              district: incentiveQuery.district,
              osb_status: incentiveQuery.osb_status,
              status: newStatus,
            })
            .eq("id", incentiveQuery.id);

          if (updateError) {
            console.error("Error updating incentive_queries:", updateError);
          } else {
            incentiveQuery.status = newStatus;
            console.log("‚úì Updated incentive query:", incentiveQuery);
          }
        }
      } else {
        const { data: newQuery, error: insertError } = await supabase
          .from("incentive_queries")
          .insert({
            session_id: sessionId,
            status: "collecting",
            sector: null,
            province: null,
            district: null,
            osb_status: null,
          })
          .select()
          .single();

        if (!insertError && newQuery) {
          incentiveQuery = newQuery;
          console.log("‚úì Started new incentive query:", incentiveQuery);
        } else {
          console.error("Error starting incentive query:", insertError);
        }
      }
    } else if (isIncentiveRelated && !sessionId) {
      incentiveQuery = {
        id: null,
        session_id: null,
        status: "collecting",
        sector: null,
        province: null,
        district: null,
        osb_status: null,
      };
      console.log("Started in-memory incentive query (no sessionId):", incentiveQuery);
    }

    const ai = getAiClient();
    const GEMINI_API_KEY = Deno.env.get("GEMINI_API_KEY");

    const generationConfig = {
      temperature: 0.05,
      maxOutputTokens: 8192,
    };

    const getSlotFillingStatus = (query: any): string => {
      const slots = ["sector", "province", "district", "osb_status"];
      const filled = slots.filter((slot) => query[slot]).length;
      return `${filled}/4 bilgi toplandƒ±`;
    };

    const getNextSlotToFill = (query: any): string => {
      if (!query.sector) return "Sekt√∂r bilgisi sor";
      if (!query.province) return "ƒ∞l bilgisi sor";
      if (!query.district) return "ƒ∞l√ße bilgisi sor";
      if (!query.osb_status) return "OSB durumu sor";
      return "T√ºm bilgiler toplandƒ± - Hesaplama yap";
    };

    const incentiveSlotFillingInstruction = incentiveQuery
      ? `
## ‚ö†Ô∏è MOD VE KURALLAR ‚ö†Ô∏è

**DURUM:** ≈ûu an yatƒ±rƒ±mcƒ±dan eksik bilgileri topluyorsun.
**MEVCUT ƒ∞LERLEME:** ${getSlotFillingStatus(incentiveQuery)}

**CEVAP STRATEJƒ∞Sƒ∞ (√ñNEMLƒ∞):**
1. **Eƒüer Kullanƒ±cƒ± Soru Sorduysa:** (√ñrn: "K√ºtahya hangi b√∂lgede?", "KDV istisnasƒ± nedir?")
¬† ¬†- **√ñNCE CEVAPLA:** Y√ºklenen belgelerden (Karar ekleri, il listeleri vb.) cevabƒ± bul ve kullanƒ±cƒ±ya ver.
¬† ¬†- **SONRA DEVAM ET:** Cevabƒ±n hemen ardƒ±ndan, eksik olan sƒ±radaki bilgiyi sor.
¬† ¬†- *√ñrnek:* "K√ºtahya ili genel te≈üvik sisteminde 4. b√∂lgede yer almaktadƒ±r. Peki yatƒ±rƒ±mƒ±nƒ±zƒ± hangi il√ßede yapmayƒ± planlƒ±yorsunuz?"

2. **Eƒüer Kullanƒ±cƒ± Sadece Veri Verdiyse:** (√ñrn: "Tekstil", "Ankara")
¬† ¬†- Kƒ±sa bir onay ver ve sƒ±radaki eksik bilgiyi sor.
¬† ¬†- Maksimum 2 c√ºmle kullan.

**Toplanan Bilgiler:**
${incentiveQuery.sector ? `‚úì Sekt√∂r: ${incentiveQuery.sector}` : "‚óã Sekt√∂r: Bekleniyor"}
${incentiveQuery.province ? `‚úì ƒ∞l: ${incentiveQuery.province}` : "‚óã ƒ∞l: Bekleniyor"}
${incentiveQuery.district ? `‚úì ƒ∞l√ße: ${incentiveQuery.district}` : "‚óã ƒ∞l√ße: Bekleniyor"}
${incentiveQuery.osb_status ? `‚úì OSB Durumu: ${incentiveQuery.osb_status}` : "‚óã OSB Durumu: Bekleniyor"}

**SONRAKƒ∞ HEDEF:** ${getNextSlotToFill(incentiveQuery)}

${
  incentiveQuery.sector && incentiveQuery.province && incentiveQuery.district && incentiveQuery.osb_status
    ? `
**HESAPLAMA ZAMANI:**
T√ºm bilgiler toplandƒ±. ≈ûimdi "tesvik_sorgulama.pdf" dosyasƒ±ndaki S√úRE√á AKI≈ûI'na [kaynak 72-73] g√∂re te≈üvik hesabƒ± yap.
`
    : ""
}
`
      : "";

    const interactiveInstructions = `
Sen bir yatƒ±rƒ±m te≈üvik danƒ±≈ümanƒ±sƒ±n. ≈ûU AN Bƒ∞LGƒ∞ TOPLAMA MODUNDASIN.

"tesvik_sorgulama.pdf" dosyasƒ±ndaki "S√úRE√á AKI≈ûI" [kaynak 62-71] ve "√ñrnek Akƒ±≈ü"a [kaynak 89-100] uymalƒ±sƒ±n.

‚ö†Ô∏è KRƒ∞Tƒ∞K KURALLAR:
1. AKILLI ANALƒ∞Z: Kullanƒ±cƒ± "√ßorap √ºretimi" veya "K√ºtahya'da yatƒ±rƒ±m" derse, bu verileri kaydet ve bir sonraki eksik veriye ge√ß.
2. TEK SORU: Her seferinde SADECE TEK Bƒ∞R soru sor.
3. PDF AKI≈ûI: 1) Sekt√∂r ‚Üí 2) ƒ∞l ‚Üí 3) ƒ∞l√ße ‚Üí 4) OSB durumu
4. ESNEKLƒ∞K (SORU CEVAPLAMA): Kullanƒ±cƒ± akƒ±≈ü sƒ±rasƒ±nda bilgi talep ederse (√ñrn: "K√ºtahya ka√ßƒ±ncƒ± b√∂lge?"), "Bilgi veremem" DEME. Belgeden (√∂zellikle 9903 Karar Ekleri) bilgiyi bul, soruyu cevapla ve akƒ±≈üa kaldƒ±ƒüƒ±n yerden devam et.

‚ö†Ô∏è YASAK DAVRANI≈ûLAR:
- Kullanƒ±cƒ±ya ders verir gibi uzun, gereksiz paragraflar yazma.
- Kullanƒ±cƒ± veri girdiƒüinde (Sekt√∂r: Demir) tekrar "Hangi sekt√∂r?" diye sorma.
`;

    const baseInstructions = `
**Sen T√ºrkiye'deki yatƒ±rƒ±m te≈üvikleri konusunda uzman bir asistansƒ±n.
**Kullanƒ±cƒ± tarafƒ±ndan sorulan bir soruyu √∂ncelikle t√ºm d√∂k√ºmanlarda ara, eƒüer sorunun cevabƒ± √∂zel kurallara uygunsa hangi kural en uygun ise ona g√∂re cevabƒ± olu≈ütur, eƒüer interaktif bir sohbet olarak algƒ±larsan "interactiveInstructions" buna g√∂re hareket et.
**T√ºm cevaplarƒ±nƒ± m√ºmk√ºn olduƒüunca Y√úKLEDƒ∞ƒûƒ∞N BELGELERE dayanarak ver.
**Sorularƒ± **T√ºrk√ße** cevapla.
**Belge i√ßeriƒüiyle √ßeli≈üen veya desteklenmeyen genellemeler yapma.

‚ö†Ô∏è √ñNEMLƒ∞: Belge i√ßeriklerini AYNEN KOPYALAMA. Bilgileri kendi c√ºmlelerinle yeniden ifade et, √∂zetle ve a√ßƒ±kla. Hi√ßbir zaman doƒürudan alƒ±ntƒ± yapma.

## ƒ∞L Lƒ∞STELEME KURALLARI (√áOK √ñNEMLƒ∞):
Bir √ºr√ºn/sekt√∂r hakkƒ±nda "hangi illerde" sorulduƒüunda:
1. Belgede ge√ßen **T√úM illeri madde madde listele** - eksik bƒ±rakma!
2. "Mersin ve Giresun illerinde..." gibi √∂zet YAPMA!
3. Her ili **ayrƒ± satƒ±rda, numaralandƒ±rarak** yaz:
   1. Mersin - [yatƒ±rƒ±m konusu a√ßƒ±klamasƒ±]
   2. Tokat - [yatƒ±rƒ±m konusu a√ßƒ±klamasƒ±]
   3. Isparta - [yatƒ±rƒ±m konusu a√ßƒ±klamasƒ±]
   ...
4. **"ve diƒüerleri", "gibi" deme** - hepsini yaz
5. Eƒüer belgede 8 il varsa, 8'ini de listele
6. ƒ∞l sayƒ±sƒ±nƒ± **yanƒ±ltƒ±cƒ± ≈üekilde azaltma**

√ñzel Kurallar:
- 9903 sayƒ±lƒ± karar, yatƒ±rƒ±m te≈üvikleri hakkƒ±nda genel bilgiler, destek unsurlarƒ± sorularƒ±, tanƒ±mlar, m√ºeyyide, devir, te≈üvik belgesi revize, tamamlama vizesi ve m√ºcbir sebep gibi idari s√ºre√ßler vb. kurallar ve ≈üartlarla ilgili soru sorulduƒüunda sorunun cevaplarƒ±nƒ± m√ºmk√ºn mertebe "9903_karar.pdf" dosyasƒ±nda ara.
- ƒ∞llerin B√∂lge Sƒ±nƒ±flandƒ±rmasƒ± sorulduƒüunda (√ñrn: K√ºtahya ka√ßƒ±ncƒ± b√∂lge?), cevabƒ± 9903 sayƒ±lƒ± kararƒ±n eklerinde veya ilgili tebliƒü dosyalarƒ±nda (EK-1 ƒ∞llerin B√∂lgesel Sƒ±nƒ±flandƒ±rmasƒ±) ara.
- 9903 sayƒ±lƒ± kararƒ±n uygulanmasƒ±na ili≈ükin usul ve esaslar, yatƒ±rƒ±m te≈üvik belgesi ba≈üvuru ≈üartlarƒ± (y√∂ntem, gerekli belgeler), hangi yatƒ±rƒ±m cinslerinin (komple yeni, tevsi, modernizasyon vb.) ve harcamalarƒ±n destek kapsamƒ±na alƒ±nacaƒüƒ±, √∂zel sekt√∂r projeleri i√ßin Stratejik Hamle Programƒ± deƒüerlendirme kriterleri ve s√ºreci, g√ºne≈ü/r√ºzgar enerjisi, veri merkezi, ≈üarj istasyonu gibi belirli yatƒ±rƒ±mlar i√ßin aranan ek ≈üartlar ile faiz/k√¢r payƒ±, sigorta primi, vergi indirimi gibi desteklerin √∂deme ve uygulama usullerine ili≈ükin bir soru geldiƒüinde, cevabƒ± √∂ncelikle ve aƒüƒ±rlƒ±klƒ± olarak "2025-1-9903_teblig.pdf" dosyasƒ± i√ßinde ara ve yanƒ±tƒ±nƒ± m√ºmk√ºn olduƒüunca bu dosyadaki h√ºk√ºmlere dayandƒ±r.
- Yerel kalkƒ±nma hamlesi, yerel yatƒ±rƒ±m konularƒ± gibi ifadelerle soru sorulduƒüunda, yada √∂rneƒüin; pektin yatƒ±rƒ±mƒ±nƒ± nerde yapabilirim gibi sorular geldiƒüinde "ykh_teblig_yatirim_konulari_listesi_yeni.pdf" dosyasƒ±nda yatƒ±rƒ±m konusu i√ßerisinde pektin kelimesi ge√ßen yatƒ±rƒ±m konularƒ±na g√∂re sorunun cevaplarƒ±nƒ± ara. Yatƒ±rƒ±m konularƒ±nda parantez i√ßerisinde bile ge√ßse onlarƒ± da dahil et.
- 9495 sayƒ±lƒ± karar kapsamƒ±nda proje bazlƒ± yatƒ±rƒ±mlar, √ßok b√ºy√ºk √∂l√ßekli yatƒ±rƒ±mlar hakkƒ±nda gelebilecek sorular sorulduƒüunda sorunun cevaplarƒ±nƒ± m√ºmk√ºn mertebe "2016-9495_Proje_Bazli.pdf" dosyasƒ±nda ara
- 9495 sayƒ±lƒ± kararƒ±n uygulanmasƒ±na y√∂nelik usul ve esaslarla ilgili tebliƒü i√ßin gelebilecek sorular sorulduƒüunda sorunun cevaplarƒ±nƒ± m√ºmk√ºn mertebe "2019-1_9495_teblig.pdf" dosyasƒ±nda ara
- HIT 30 programƒ± kapsamƒ±nda elektrikli ara√ß, batarya, veri merkezleri ve alt yapƒ±larƒ±, yarƒ± iletkenlerin √ºretimi, Ar-Ge, kuantum, robotlar vb. yatƒ±rƒ±mlarƒ± i√ßin gelebilecek sorular sorulduƒüunda sorunun cevaplarƒ±nƒ± m√ºmk√ºn mertebe "Hit30.pdf" dosyasƒ±nda ara
- Yatƒ±rƒ±m taahh√ºtl√º avans kredisi, ytak hakkƒ±nda gelebilecek sorular sorulduƒüunda sorunun cevaplarƒ±nƒ± m√ºmk√ºn mertebe "ytak.pdf" ve "ytak_hesabi.pdf" dosyalarƒ±nda ara
- 9903 saylƒ± karar ve karara ili≈ükin tebliƒüde belirlenmemi≈ü "teknoloji hamlesi programƒ±" hakkƒ±nda programƒ±n uygulama esaslarƒ±nƒ±, baƒüƒ±msƒ±z deƒüerlendirme s√ºre√ßleri netle≈ütirilmi≈ü ve T√úBƒ∞TAK'ƒ±n Ar-Ge bile≈üenlerini deƒüerlendirme rol√º, Komite deƒüerlendirme kriterleri, ba≈üvurularƒ± hakkƒ±nda gelebilecek sorular sorulduƒüunda sorunun cevaplarƒ±nƒ± m√ºmk√ºn mertebe "teblig_teknoloji_hamlesi_degisiklik.pdf" dosyasƒ±nda ara 
- Bir yatƒ±rƒ±m konusu sorulursa veya bir yatƒ±rƒ±m konusu hakkƒ±nda veya nace kodu sorulursa "sectorsearching.xlsx" dosyasƒ±nda ara.
- Etuys i√ßin "Sistemsel Sorunlar (A√ßƒ±lmama, ƒ∞mza Hatasƒ± vs.)", "Belge Ba≈üvurusuna ƒ∞li≈ükin sorular", "Devir ƒ∞≈ülemleri", "Revize Ba≈üvurularƒ±", "Yerli ve ƒ∞thal Ger√ßekle≈ütirmeler-Fatura ve G√ºmr√ºk ƒ∞≈ülemleri", "Vergi ƒ∞stisna Yazƒ±sƒ± Alma ƒ∞≈ülemleri", "Tamamlama Vizesi ƒ∞≈ülemleri", ve "hata mesajlarƒ±" ile ilgili sistemsel sorunlarda √ß√∂z√ºm arayanlar i√ßin "etuys_systemsel_sorunlar.txt" dosyasƒ±nda ara.
- Bilgileri verirken mutlaka kendi c√ºmlelerinle a√ßƒ±kla, √∂zetle ve yeniden ifade et. Belge i√ßeriƒüini kelimesi kelimesine kopyalama.
- Eƒüer y√ºklenen belgeler soruyu kapsamƒ±yorsa "Bu soru y√ºklenen belgelerin kapsamƒ± dƒ±≈üƒ±nda, sadece genel kavramsal a√ßƒ±klama yapabilirim." diye belirt ve genel kavramƒ± √ßok kƒ±sa √∂zetle.
- En son satƒ±ra detaylƒ± bilgi almak i√ßin ilgili ilin yatƒ±rƒ±m destek ofisi ile ileti≈üime ge√ßebilirsiniz.
`;

    const normalizedUserMessage = normalizeRegionNumbers(lastUserMessage.content);
    const messagesForGemini = [
      ...messages.slice(0, -1),
      {
        ...lastUserMessage,
        content: normalizedUserMessage,
      },
    ];

    const systemPrompt =
      incentiveQuery && incentiveQuery.status === "collecting"
        ? baseInstructions + "\n\n" + interactiveInstructions + "\n\n" + incentiveSlotFillingInstruction
        : baseInstructions;

    console.log("=== Calling Gemini ===");
    console.log("systemPrompt length:", systemPrompt.length);

    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash",
      contents: messagesForGemini
        .map((m: any) => ({
          role: m.role === "user" ? "user" : "model",
          parts: [{ text: m.content }],
        }))
        // FIX 3: Filter out assistant messages containing the leaked tool content
        // to prevent the AI from learning the bad behavior.
        .filter((m: any) => m.role === "user" || !m.parts[0].text.includes("tool_code\nprint(file_search.query")),
      config: {
        ...generationConfig,
        systemInstruction: systemPrompt,
        tools: [
          {
            fileSearch: {
              fileSearchStoreNames: [storeName],
            },
          },
        ],
      },
    });

    console.log("=== Gemini response received ===");

    let { finishReason, groundingChunks, textOut } = extractTextAndChunks(response);

    console.log("üìä Initial Response Analysis:", {
      textLength: textOut.length,
      textPreview: textOut.substring(0, 150),
      chunksCount: groundingChunks.length,
      finishReason,
    });

    // Extract main keyword from user query for validation (e.g., "pektin" from "pektin hangi illerde")
    const queryKeywords = normalizedUserMessage
      .toLowerCase()
      .replace(/hangi (il|≈üehir|yer|yerde|yerlerde|illerde)|nerede|nerelerde|desteklen.*|var|√ºretim/gi, "")
      .trim()
      .split(/\s+/)
      .filter((word) => word.length > 3); // Min 4 character words

    console.log("üîç Extracted query keywords for validation:", queryKeywords);

    // ============= ADIM 1: BO≈û YANIT KONTROL√ú VE DYNAMIC RETRY =============
    if (!textOut || textOut.trim().length === 0) {
      console.warn("‚ö†Ô∏è Empty response detected! Triggering Gemini-powered retry...");

      const retryPrompt = `
üîç √ñNCEKƒ∞ ARAMADA SONU√á BULUNAMADI - DERƒ∞N ARAMA MODUNA GE√áƒ∞Lƒ∞YOR

Kullanƒ±cƒ±nƒ±n Orijinal Sorusu: "${normalizedUserMessage}"

G√ñREV:
1. Bu soruyu yanƒ±tlamak i√ßin √ñNCE ≈üu soruyu kendin yanƒ±tla:
   - Ana anahtar kelime nedir? (√ñrn: "krom cevheri" ‚Üí "krom")
   - Hangi e≈ü anlamlƒ±larƒ± aramam gerek? (√ñrn: "krom madenciliƒüi", "krom √ºretimi", "krom rezervi")
   - Hangi √ºst kategoriye ait? (√ñrn: "maden", "metal", "hammadde")
   - ƒ∞lgili NACE kodlarƒ± var mƒ±?

2. ≈ûƒ∞MDƒ∞ bu alternatif terimlerle File Search yap:
   - Dosyalar: ykh_teblig_yatirim_konulari_listesi_yeni.pdf, 9903_karar.pdf, sectorsearching.xlsx
   - SATIR SATIR TARA, her sayfayƒ± kontrol et
   - Her aramayƒ± farklƒ± terimlerle TEKRARLA (en az 3 varyasyon)

3. BULDUƒûUN T√úM SONU√áLARI Lƒ∞STELE:
   - ƒ∞l adlarƒ±nƒ± eksik bƒ±rakma
   - "ve diƒüerleri" deme
   - Eƒüer belgede ge√ßen 8 il varsa, 8'ini de yaz

4. Eƒüer ger√ßekten hi√ßbir sonu√ß yoksa:
   "Bu konuda doƒürudan destek saƒülayan bir yatƒ±rƒ±m konusu bulunamamƒ±≈ütƒ±r. Ancak [√úST KATEGORƒ∞] kapsamƒ±nda deƒüerlendirilebilir" de.

BA≈ûLA! üöÄ
`;

      const retryResponse = await ai.models.generateContent({
        model: "gemini-2.5-flash",
        contents: [
          {
            role: "user",
            parts: [{ text: retryPrompt }],
          },
        ],
        config: {
          temperature: 0.05, // Maksimum deterministik
          maxOutputTokens: 8192,
          systemInstruction: baseInstructions,
          tools: [{ fileSearch: { fileSearchStoreNames: [storeName] } }],
        },
      });

      const retryResult = extractTextAndChunks(retryResponse);
      console.log("üîÑ Retry Result:", {
        textLength: retryResult.textOut.length,
        chunksCount: retryResult.groundingChunks.length,
      });

      // Retry sonrasƒ± hala bo≈üsa fallback
      if (!retryResult.textOut || retryResult.textOut.trim().length === 0) {
        console.error("‚ùå Retry failed - returning fallback message");
        return new Response(
          JSON.stringify({
            text: "√úzg√ºn√ºm, belgelerimde bu konuyla ilgili doƒürudan bilgi bulamadƒ±m. L√ºtfen sorunuzu farklƒ± kelimelerle ifade ederek tekrar deneyin veya ilgili Yatƒ±rƒ±m Destek Ofisi ile ileti≈üime ge√ßin.",
            groundingChunks: [],
            emptyResponse: true,
            retriedWithDynamicSearch: true,
          }),
          { headers: { ...corsHeaders, "Content-Type": "application/json" } },
        );
      }

      // Retry ba≈üarƒ±lƒ±! Yeni sonu√ßlarƒ± kullan
      console.log("‚úÖ Retry successful - using new results");
      textOut = retryResult.textOut;
      groundingChunks = retryResult.groundingChunks;
      finishReason = retryResult.finishReason;

      // Enrichment i≈ülemini retry sonu√ßlarƒ± i√ßin de yapacaƒüƒ±z (a≈üaƒüƒ±da)
    }

    // ============= ADIM 2: ANAHTAR KELƒ∞ME VALƒ∞DASYONU (KEYWORD FILTERING) =============
    // Geni≈ületilmi≈ü il sorgusu pattern'i
    const isProvinceQuery =
      /hangi (il|≈üehir|yer|yerde|yerlerde|illerde)|nerede|nerelerde|nereye|ka√ß il|tek il|birka√ß il|hangi b√∂lge|desteklenen iller|desteklenen ≈üehirler/i.test(
        normalizedUserMessage,
      );

    // VALIDATE grounding chunks contain query keywords (for province queries)
    // CRITICAL FIX: Only include chunks where investment topic ACTUALLY mentions the searched keyword
    let validatedChunks = groundingChunks;
    if (isProvinceQuery && queryKeywords.length > 0) {
      const mainKeyword = queryKeywords[0]; // Primary keyword (e.g., "pektin")
      
      validatedChunks = groundingChunks.filter((chunk) => {
        const chunkContent = (chunk.retrievedContext?.text || "").toLowerCase();
        
        // Extract investment topic from chunk (text between "- " and newline or end)
        const topicMatch = chunkContent.match(/(?:^|\n)(.+?(?:\(.*?\))?)\s*(?:\n|$)/);
        const investmentTopic = topicMatch ? topicMatch[1] : chunkContent;
        
        // Check if the main keyword appears in the investment topic description
        // This prevents "Fƒ±ndƒ±k Kabuƒüu... (aktif karbon...)" from matching "pektin" queries
        const topicContainsKeyword = investmentTopic.includes(mainKeyword);
        
        if (!topicContainsKeyword) {
          console.log(`‚ùå FILTERED chunk - keyword "${mainKeyword}" NOT in investment topic:`, {
            title: chunk.retrievedContext?.title,
            investmentTopic: investmentTopic.substring(0, 150),
          });
        } else {
          console.log(`‚úÖ VALID chunk - keyword "${mainKeyword}" found in:`, {
            title: chunk.retrievedContext?.title,
            investmentTopic: investmentTopic.substring(0, 150),
          });
        }

        return topicContainsKeyword;
      });

      console.log(
        `üîç Strict keyword validation: ${groundingChunks.length} chunks ‚Üí ${validatedChunks.length} validated chunks`,
      );

      // Update groundingChunks with validated ones
      groundingChunks = validatedChunks;
    }

    // Ger√ßek T√ºrkiye il listesiyle filtreleme
    const foundProvinces = TURKISH_PROVINCES.filter((province) => textOut.includes(province));
    const uniqueProvinces = [...new Set(foundProvinces)];

    console.log("üîç Province Query Analysis:", {
      isProvinceQuery,
      foundProvinces: uniqueProvinces.length,
      provinces: uniqueProvinces.slice(0, 10).join(", ") + (uniqueProvinces.length > 10 ? "..." : ""),
    });

    if (isProvinceQuery && uniqueProvinces.length > 0 && uniqueProvinces.length < 3) {
      console.warn(
        `‚ö†Ô∏è Insufficient province results (${uniqueProvinces.length}/expected ‚â•3). Triggering feedback loop...`,
      );

      const feedbackPrompt = `
‚ö†Ô∏è √ñNCEKƒ∞ CEVABINIZ YETERSƒ∞Z BULUNDU - GENƒ∞≈ûLETƒ∞LMƒ∞≈û ARAMA GEREKLƒ∞

Kullanƒ±cƒ± Sorusu: "${normalizedUserMessage}"

Senin √ñnceki Cevabƒ±n: "${textOut.substring(0, 300)}..."

SORUN: Sadece ${uniqueProvinces.length} il buldun (${uniqueProvinces.join(", ")}). 
Bu sayƒ± ≈ü√ºpheli derecede az!

YENƒ∞ G√ñREV:
1. ykh_teblig_yatirim_konulari_listesi_yeni.pdf dosyasƒ±nƒ± BA≈ûTAN SONA yeniden tara
2. Ana anahtar kelimenin (${normalizedUserMessage}) t√ºm varyasyonlarƒ±nƒ± ara:
   - Tam e≈üle≈üme
   - K√∂k kelime
   - √úst kategori
   - Alt √ºr√ºn gruplarƒ±
3. Her sayfayƒ± kontrol et - ATLAMA
4. Bulduƒüun T√úM illeri madde madde listele
5. Eƒüer ger√ßekten bu kadar azsa, yanƒ±tƒ±na ≈üunu ekle:
   "‚ÑπÔ∏è Not: Sistemimizde sadece bu ${uniqueProvinces.length} ilde bu konuyla ilgili doƒürudan kayƒ±t bulunmaktadƒ±r."

BA≈ûLA! üîç
`;

      const feedbackResponse = await ai.models.generateContent({
        model: "gemini-2.5-flash",
        contents: [
          {
            role: "user",
            parts: [{ text: feedbackPrompt }],
          },
        ],
        config: {
          temperature: 0.05, // Daha da deterministik
          maxOutputTokens: 8192,
          systemInstruction: baseInstructions,
          tools: [{ fileSearch: { fileSearchStoreNames: [storeName] } }],
        },
      });

      const feedbackResult = extractTextAndChunks(feedbackResponse);
      console.log("üîÅ Feedback Loop Result:", {
        textLength: feedbackResult.textOut.length,
        originalProvinces: uniqueProvinces.length,
        newText: feedbackResult.textOut.substring(0, 200),
      });

      // Feedback loop sonrasƒ± daha iyi sonu√ß varsa kullan
      if (feedbackResult.textOut && feedbackResult.textOut.length > textOut.length) {
        console.log("‚úÖ Feedback loop improved results - using enhanced response");
        textOut = feedbackResult.textOut;
        groundingChunks = feedbackResult.groundingChunks;
        finishReason = feedbackResult.finishReason;

        // Flag ekle ki frontend bilsin
        const finalWithFeedback = await enrichAndReturn(textOut, groundingChunks, storeName, GEMINI_API_KEY || "", {
          enhancedViaFeedbackLoop: true,
        });
        return finalWithFeedback;
      }
    }

    // ============= SAFETY CHECK =============
    if (finishReason === "SAFETY") {
      console.log("‚ö†Ô∏è Response blocked due to:", finishReason);

      return new Response(
        JSON.stringify({
          error:
            "√úzg√ºn√ºm, bu soruya g√ºvenli bir ≈üekilde cevap veremiyorum. L√ºtfen sorunuzu farklƒ± ≈üekilde ifade etmeyi deneyin.",
          blocked: true,
          reason: finishReason,
        }),
        {
          status: 400,
          headers: { ...corsHeaders, "Content-Type": "application/json" },
        },
      );
    }

    let finalText = textOut;

    // Normal flow i√ßin de enrichment yap
    return await enrichAndReturn(finalText, groundingChunks, storeName, GEMINI_API_KEY || "");
  } catch (error) {
    console.error("‚ùå Error in chat-gemini:", error);
    return new Response(
      JSON.stringify({
        error: error instanceof Error ? error.message : "Unknown error",
      }),
      {
        status: 500,
        headers: { ...corsHeaders, "Content-Type": "application/json" },
      },
    );
  }
});

// ============= HELPER FUNCTION: ENRICHMENT =============
async function enrichAndReturn(
  textOut: string,
  groundingChunks: any[],
  storeName: string,
  apiKey: string,
  extraFlags: Record<string, any> = {},
) {
  // Extract document IDs
  const docIds = groundingChunks
    .map((c: any) => {
      const rc = c.retrievedContext ?? {};
      if (rc.documentName) return rc.documentName;
      if (rc.title) {
        return rc.title.startsWith("fileSearchStores/") ? rc.title : `${storeName}/documents/${rc.title}`;
      }
      return null;
    })
    .filter((id: string | null): id is string => !!id);

  const uniqueDocIds = [...new Set(docIds)];
  const documentMetadataMap: Record<string, string> = {};

  console.log("=== Fetching Document Metadata ===");
  console.log("Unique document IDs:", uniqueDocIds);

  const normalizeDocumentName = (rawId: string): string => {
    if (rawId.startsWith("fileSearchStores/")) return rawId;
    return `${storeName}/documents/${rawId}`;
  };

  for (const rawId of uniqueDocIds) {
    try {
      const documentName = normalizeDocumentName(rawId);
      const url = `https://generativelanguage.googleapis.com/v1beta/${documentName}?key=${apiKey}`;
      console.log(`Fetching metadata for: ${documentName}`);

      const docResp = await fetch(url);
      if (docResp.ok) {
        const docData = await docResp.json();
        const customMeta = docData.customMetadata || [];

        const filenameMeta = customMeta.find((m: any) => m.key === "Dosya" || m.key === "fileName");

        if (filenameMeta) {
          const enrichedName = filenameMeta.stringValue || filenameMeta.value || rawId;
          documentMetadataMap[rawId] = enrichedName;
          console.log(`‚úì Enriched ${rawId} -> ${enrichedName}`);
        }
      } else {
        console.error(`Failed to fetch ${documentName}: ${docResp.status}`);
      }
    } catch (e) {
      console.error(`Error fetching metadata for ${rawId}:`, e);
    }
  }

  // Enrich chunks
  const enrichedChunks = groundingChunks.map((chunk: any) => {
    const rc = chunk.retrievedContext ?? {};
    const rawId = rc.documentName || rc.title || null;

    return {
      ...chunk,
      enrichedFileName: rawId ? (documentMetadataMap[rawId] ?? null) : null,
    };
  });

  console.log("=== Enrichment Complete ===");

  const result = {
    text: textOut,
    groundingChunks: enrichedChunks,
    ...extraFlags,
  };

  return new Response(JSON.stringify(result), {
    headers: { ...corsHeaders, "Content-Type": "application/json" },
  });
}
